{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import hyperparams as hp\n",
    "import numpy as np\n",
    "import math\n",
    "import glu\n",
    "import positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder Network\n",
    "    \"\"\"\n",
    "    def __init__(self, para):\n",
    "        \"\"\"\n",
    "        :param para: dictionary that contains all parameters\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        #self.alpha = nn.Parameter(t.ones(1))\n",
    "        \n",
    "        self.emb_phone = nn.Embedding(para['phone_size'], para['emb_dim'])\n",
    "        #full connected\n",
    "        self.fc_1 = nn.Linear(para['emb_dim'], para['GLU_in_dim'])\n",
    "        \n",
    "        self.GLU = glu.GLU(para['num_layers'], para['hidden_size'], para['kernel_size'], para['dropout'], para['GLU_in_dim'])\n",
    "        \n",
    "        self.fc_2 = nn.Linear(para['hidden_size'], para['emb_dim'])\n",
    "        \n",
    "    def refine(self, align_phone):\n",
    "        '''filter silence phone and repeat phone'''\n",
    "        out = []\n",
    "        length = []\n",
    "        batch_size = align_phone.shape[0]\n",
    "        max_length = align_phone.shape[1]\n",
    "        before = 0\n",
    "        for i in range(batch_size):\n",
    "            line = []\n",
    "            for j in range(max_length):\n",
    "                if align_phone[i][j] == 1 or align_phone[i][j] == 0:      #silence phone or padding\n",
    "                    continue\n",
    "                elif align_phone[i][j] == before:   #the same with the former phone\n",
    "                    continue\n",
    "                else:\n",
    "                    before = align_phone[i][j]\n",
    "                    line.append(before)\n",
    "            out.append(line)\n",
    "            length.append(len(line))\n",
    "        \n",
    "        #pad 0\n",
    "        seq_length = max(length)\n",
    "        Data = np.zeros((batch_size, seq_length))\n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_length):\n",
    "                if j < len(out[i]):\n",
    "                    Data[i][j] = out[i][j]\n",
    "                    \n",
    "        return torch.from_numpy(Data).type(torch.LongTensor)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input dim: [batch_size, text_phone_length]\n",
    "        output dim : [batch_size, text_phone_length, embedded_dim]\n",
    "        \"\"\"\n",
    "        input = self.refine(input)\n",
    "        print(input)\n",
    "        embedded_phone = self.emb_phone(input)    # [src len, batch size, emb dim]\n",
    "        print(embedded_phone.shape,embedded_phone)\n",
    "        glu_out = self.GLU(self.fc_1(embedded_phone))\n",
    "        print(glu_out.shape)\n",
    "        glu_out = self.fc_2(torch.transpose(glu_out, 1, 2))\n",
    "        print(glu_out.shape,glu_out)\n",
    "        out = embedded_phone + glu_out\n",
    "        print(out.shape,out)\n",
    "        out = out *  math.sqrt(0.5)\n",
    "        print(out.shape,out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Postnet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder Postnet\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Encoder_Postnet, self, seq_length).__init__()\n",
    "        #length of sequence = number of frames\n",
    "        self.fc = nn.Linear(seq_length, seq_length)\n",
    "         \n",
    "    def aligner(encoder_out, align_phone):\n",
    "        return\n",
    "        \n",
    "    def forward(self, encoder_out, align_phone, pitch, beats):\n",
    "        aligner_out = aligner(encoder_out, align_phone)\n",
    "        pitch = self.fc(pitch)\n",
    "        out = aligner_out + pitch\n",
    "        beats_avg = len(beats) / sum(beats)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 5, 6, 0],\n",
      "        [4, 2, 3, 7]])\n",
      "torch.Size([2, 4, 256]) tensor([[[ 4.7961e-01,  1.7784e-01, -1.9790e-01,  ...,  9.5143e-02,\n",
      "           1.3601e-01,  6.3780e-01],\n",
      "         [ 1.5068e+00, -1.4208e+00, -2.5689e-01,  ..., -4.8902e-01,\n",
      "           2.7645e-01,  1.3198e+00],\n",
      "         [-1.6917e+00,  2.9500e-01,  6.6839e-01,  ..., -3.9285e-01,\n",
      "           9.0842e-01, -6.3534e-01],\n",
      "         [ 1.4873e+00, -1.1569e+00, -9.7593e-01,  ...,  6.0804e-01,\n",
      "          -4.3319e-02,  4.8037e-01]],\n",
      "\n",
      "        [[ 3.8978e-01, -3.6042e-01,  5.8337e-01,  ..., -3.7904e-02,\n",
      "          -6.6994e-01, -4.7379e-01],\n",
      "         [-7.8871e-01,  2.1669e+00, -2.1239e-01,  ...,  1.3861e-03,\n",
      "           7.2562e-01, -1.4388e+00],\n",
      "         [ 4.7961e-01,  1.7784e-01, -1.9790e-01,  ...,  9.5143e-02,\n",
      "           1.3601e-01,  6.3780e-01],\n",
      "         [ 1.1055e-01, -2.7115e-01,  7.4965e-01,  ..., -4.9486e-01,\n",
      "          -1.1627e+00,  4.7236e-01]]], grad_fn=<EmbeddingBackward>)\n",
      "torch.Size([2, 64, 4])\n",
      "torch.Size([2, 4, 256]) tensor([[[ 0.0536, -0.1867,  0.0313,  ...,  0.1926,  0.1341, -0.0876],\n",
      "         [-0.1018, -0.0209,  0.1656,  ...,  0.1899,  0.0846, -0.2535],\n",
      "         [ 0.0717, -0.1923,  0.0785,  ...,  0.2986,  0.0330, -0.0558],\n",
      "         [-0.0660, -0.0996,  0.0500,  ...,  0.0244,  0.2177, -0.0489]],\n",
      "\n",
      "        [[ 0.0088, -0.2420,  0.2515,  ...,  0.0886, -0.0373, -0.0781],\n",
      "         [ 0.0335, -0.1527, -0.1318,  ...,  0.2735, -0.2377, -0.1408],\n",
      "         [-0.0765, -0.2744, -0.0339,  ...,  0.1585,  0.1760, -0.2500],\n",
      "         [-0.1694, -0.0495, -0.0567,  ...,  0.1787,  0.1101, -0.1648]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 256]) tensor([[[ 0.5332, -0.0089, -0.1666,  ...,  0.2878,  0.2701,  0.5502],\n",
      "         [ 1.4050, -1.4417, -0.0913,  ..., -0.2991,  0.3610,  1.0663],\n",
      "         [-1.6201,  0.1027,  0.7469,  ..., -0.0943,  0.9414, -0.6912],\n",
      "         [ 1.4214, -1.2565, -0.9259,  ...,  0.6325,  0.1744,  0.4315]],\n",
      "\n",
      "        [[ 0.3986, -0.6024,  0.8349,  ...,  0.0507, -0.7073, -0.5519],\n",
      "         [-0.7552,  2.0143, -0.3442,  ...,  0.2749,  0.4879, -1.5796],\n",
      "         [ 0.4031, -0.0966, -0.2318,  ...,  0.2536,  0.3120,  0.3879],\n",
      "         [-0.0589, -0.3207,  0.6930,  ..., -0.3162, -1.0527,  0.3076]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 256]) tensor([[[ 0.3770, -0.0063, -0.1178,  ...,  0.2035,  0.1910,  0.3891],\n",
      "         [ 0.9935, -1.0195, -0.0646,  ..., -0.2115,  0.2553,  0.7540],\n",
      "         [-1.1456,  0.0726,  0.5282,  ..., -0.0667,  0.6657, -0.4887],\n",
      "         [ 1.0051, -0.8885, -0.6547,  ...,  0.4472,  0.1233,  0.3051]],\n",
      "\n",
      "        [[ 0.2819, -0.4260,  0.5903,  ...,  0.0358, -0.5001, -0.3903],\n",
      "         [-0.5340,  1.4243, -0.2434,  ...,  0.1944,  0.3450, -1.1170],\n",
      "         [ 0.2851, -0.0683, -0.1639,  ...,  0.1794,  0.2206,  0.2743],\n",
      "         [-0.0416, -0.2267,  0.4900,  ..., -0.2236, -0.7444,  0.2175]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "para = {'phone_size':67, 'emb_dim':256, 'GLU_in_dim':64, 'num_layers':6, 'kernel_size':3, 'hidden_size':64, 'dropout':0.1 }\n",
    "encoder = Encoder(para)\n",
    "phone = torch.tensor([[1,3,3,3,3,5,5,6,0,0,0],[1,1,1,4,2,2,2,3,7,1,1]])\n",
    "out = encoder(phone)\n",
    "#print(out.shape,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-404168233df6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositional_encoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/林海斓/SVS/SVS_system/model/positional_encoding.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, dropout, max_len)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         div_term = torch.exp(\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             * (-math.log(10000.0) / d_model))\n\u001b[1;32m     23\u001b[0m         \u001b[0mpe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiv_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "beats = [[[0,1,0,0,0,1,0]],[[0,0,0,1,1,0,1]]]\n",
    "pos = positional_encoding.PositionalEncoding(7)\n",
    "out = pos(beats)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
